{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/nfs/lab/varpred/Final_Results/final_matrices/\"\n",
    "file_path = \"./\"\n",
    "t1d_mat = file_path + \"T1D_final_short.bed\"\n",
    "t2d_mat = file_path + \"T2D_final_short.bed\"\n",
    "topmed_mat = file_path + \"topmed_final.bed\"\n",
    "proba_threshold_high = 0.8\n",
    "proba_threshold_low = 0.000005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data from csv\n",
    "t1d_data_raw = pandas.read_csv(t1d_mat, sep='\\s+')\n",
    "\n",
    "# Splitting labels and data\n",
    "t1d_labels_raw = t1d_data_raw[\"Probability\"]\n",
    "t1d_data_raw = t1d_data_raw.drop(['VarID', 'Probability'], axis=1)\n",
    "\n",
    "# Removing imbalance columns\n",
    "t1d_data = t1d_data.drop(columns=[col for col in t1d_data.columns if 'imbal' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical labelling\n",
    "def label_prob(prob, prob_threshold_high, prob_threshold_low):\n",
    "    if prob > prob_threshold_high:\n",
    "        return 1\n",
    "    elif prob < prob_threshold_low:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Split unknown and known data\n",
    "def sort_data(data, labels):\n",
    "    known_data_bool = labels != -1\n",
    "    all_data = data.copy(deep=True)\n",
    "    all_data.insert(len(all_data.columns), 'label', labels)\n",
    "    all_data.insert(len(all_data.columns), 'known', known_data_bool)\n",
    "    all_known_data = all_data[all_data.known == True]\n",
    "    all_unknown_data = all_data[all_data.known == False]\n",
    "    known_data = all_known_data.drop(['label', 'known'], axis=1)\n",
    "    known_labels = all_known_data['label']\n",
    "    unknown_data = all_unknown_data.drop(['label', 'known'], axis=1)\n",
    "    unknown_labels = all_unknown_data['label']\n",
    "    \n",
    "    return all_known_data, unknown_data, known_data, known_labels, unknown_data, unknown_labels\n",
    "\n",
    "\n",
    "def create_splitter(known_data, unknown_data):\n",
    "    ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "    splits = ss.split(known_data)\n",
    "\n",
    "    def custom_splitter(splits):\n",
    "        for train_index, test_index in splits:\n",
    "            train_index = (known_data.iloc[train_index].append(unknown_data)).index.values\n",
    "#             train_index = np.append(train_index, list(unknown_data.index.values))\n",
    "            test_index = (known_data.iloc[test_index]).index.values\n",
    "            yield train_index, test_index\n",
    "            \n",
    "    return splits, custom_splitter\n",
    "\n",
    "\n",
    "def perform_cv(model, data, labels):\n",
    "    all_known_data, unknown_data, known_data, known_labels, unknown_data, unknown_labels = sort_data(data, labels)\n",
    "    splits, custom_splitter = create_splitter(known_data, unknown_data)\n",
    "    cv_score = cross_val_score(model, data, y=labels, cv=custom_splitter(splits), verbose=1, n_jobs=1)\n",
    "    return np.mean(cv_score)\n",
    "\n",
    "def cv(model, data, labels):\n",
    "    all_known_data, unknown_data, known_data, known_labels, unknown_data, unknown_labels = sort_data(data, labels)\n",
    "    ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "    splits = ss.split(known_data)\n",
    "    \n",
    "    total_score = 0\n",
    "    num = 0\n",
    "    for train_idx, test_idx in splits:\n",
    "        train_data = known_data.iloc[train_idx].append(unknown_data)\n",
    "        test_data = known_data.iloc[test_idx]\n",
    "        train_labels = known_labels.iloc[train_idx].append(unknown_labels)\n",
    "        test_labels = known_labels.iloc[test_idx]\n",
    "\n",
    "        model.fit(train_data, train_labels)\n",
    "\n",
    "        # Predict on test\n",
    "        pred_labels = model.predict(test_data)\n",
    "\n",
    "        # Measure accuracy\n",
    "        score = accuracy_score(pred_labels, test_labels)\n",
    "        print(\"Score\", score)\n",
    "        total_score += score\n",
    "        num += 1\n",
    "\n",
    "    print(\"Avg:\", total_score / num)\n",
    "    return total_score / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high:  0.01 low 7e-06:Positive 589; Negative 2094; Unlabelled 21456; \n",
      "% positive 0.024400347984589253\n",
      "% negative 0.08674758689258047\n",
      "positive to negative ratio 0.281279847182426\n",
      "labelled to unlabelled ratio 0.12504660700969425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7749627421758569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7719821162444114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7794336810730254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.767511177347243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/semi_supervised/_label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 0.7943368107302533\n",
      "Avg: 0.777645305514158\n"
     ]
    }
   ],
   "source": [
    "t1d_data_raw = pandas.read_csv(t1d_mat, sep='\\s+')\n",
    "t1d_var_data = t1d_data_raw['VarID']\n",
    "t1d_prob = t1d_data_raw['Probability']\n",
    "\n",
    "hthresh = 0.01\n",
    "lthresh = 0.000007\n",
    "\n",
    "# Label points based on prob thresholds\n",
    "print(\"high: \", hthresh, \"low\", lthresh, end=':')\n",
    "print(\"Positive\", len(t1d_labels[t1d_labels > hthresh]), end='; ')\n",
    "print(\"Negative\", len(t1d_labels[t1d_labels < lthresh]), end='; ')\n",
    "print(\"Unlabelled\", len(t1d_labels[(t1d_labels <= hthresh) & (t1d_labels >= lthresh)]), end='; ')\n",
    "print(\"\")\n",
    "t1d_labels_thresh = t1d_labels.apply(lambda row: label_prob(row, hthresh, lthresh))\n",
    "\n",
    "# Data stats\n",
    "num_pos = len(t1d_labels_thresh[t1d_labels_thresh == 1])\n",
    "num_neg = len(t1d_labels_thresh[t1d_labels_thresh == 0])\n",
    "num_unlabelled = len(t1d_labels_thresh[t1d_labels_thresh == -1])\n",
    "print('% positive', num_pos / (num_neg + num_unlabelled + num_pos))\n",
    "print('% negative', num_neg / (num_neg + num_unlabelled + num_pos))\n",
    "print('positive to negative ratio', num_pos / num_neg)\n",
    "print('labelled to unlabelled ratio', (num_pos + num_neg) / num_unlabelled)\n",
    "\n",
    "model = LabelSpreading(kernel='rbf', alpha=0.2, gamma=20)\n",
    "norm_model = make_pipeline(MinMaxScaler(), model)\n",
    "\n",
    "cv(model, t1d_data, t1d_labels_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
